{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "000_pyCuda_deviceQuery.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM9tDgM3npwLj5nlkv7c1AZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AEW2015/fpga-colab/blob/main/HPC_for_Versal/pyCuda/000_deviceQuery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CUDA device query example with python!\n"
      ],
      "metadata": {
        "id": "iG61i0n_KHI8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uutWlYM5Hty9",
        "outputId": "37dfa3c9-a47f-40fc-aacf-8e89423a3cb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Aug 31 04:18:39 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pycuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqYpo3cIHzji",
        "outputId": "1a56c1c0-c385-40c2-e3e7-1c94cf14f034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pycuda\n",
            "  Downloading pycuda-2022.1.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 28.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mako\n",
            "  Downloading Mako-1.2.2-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 9.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting pytools>=2011.2\n",
            "  Downloading pytools-2022.1.12.tar.gz (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 9.1 MB/s \n",
            "\u001b[?25hCollecting platformdirs>=2.2.0\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda) (4.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (2.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->mako->pycuda) (3.8.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2022.1-cp37-cp37m-linux_x86_64.whl size=629484 sha256=6266f2d0c0078c6e2fcc2441d22025e20f9dd621a914ea706a329c40b7fb9ced\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/53/c9/caa05618e686df51f017d8a9923f38d915ce31df67ab6628e6\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2022.1.12-py2.py3-none-any.whl size=65034 sha256=9b361e4736396176cda4054e4827ab66caabf9059feb5fa8a45cf380a5bde283\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/5e/9e/76d7430e116b7cab0016fbabb26b896daae1946a3f7dea9915\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: platformdirs, pytools, mako, pycuda\n",
            "Successfully installed mako-1.2.2 platformdirs-2.5.2 pycuda-2022.1 pytools-2022.1.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda\n",
        "import pycuda.driver as drv\n",
        "drv.init()\n",
        "\n",
        "print ('CUDA device query (PyCUDA version) \\n')\n",
        "\n",
        "print ('Detected {} CUDA Capable device(s) \\n'.format(drv.Device.count()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzmdThoFI8Uj",
        "outputId": "7d9a55f9-1b8a-4894-b198-219833e71cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA device query (PyCUDA version) \n",
            "\n",
            "Detected 1 CUDA Capable device(s) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_device = drv.Device(0)\n",
        "print ('Device {}: {}'.format( i, gpu_device.name() ))\n",
        "compute_capability = float( '%d.%d' % gpu_device.compute_capability() )\n",
        "print ('\\t Compute Capability: {}'.format(compute_capability))\n",
        "print ('\\t Total Memory: {} megabytes'.format(gpu_device.total_memory()//(1024**2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG22weNeI-v7",
        "outputId": "52ed9725-fc8b-4da2-f0f3-12d9e94c9782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device 0: Tesla T4\n",
            "\t Compute Capability: 7.5\n",
            "\t Total Memory: 15109 megabytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device_attributes_tuples = gpu_device.get_attributes()\n",
        "for i in device_attributes_tuples:\n",
        "    print(i,device_attributes_tuples[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uOR-hcTJC27",
        "outputId": "1c7cd4ca-b9c8-4ab5-9636-5a1a8a9ad142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ASYNC_ENGINE_COUNT 3\n",
            "CAN_MAP_HOST_MEMORY 1\n",
            "CAN_USE_HOST_POINTER_FOR_REGISTERED_MEM 1\n",
            "CLOCK_RATE 1590000\n",
            "COMPUTE_CAPABILITY_MAJOR 7\n",
            "COMPUTE_CAPABILITY_MINOR 5\n",
            "COMPUTE_MODE DEFAULT\n",
            "COMPUTE_PREEMPTION_SUPPORTED 1\n",
            "CONCURRENT_KERNELS 1\n",
            "CONCURRENT_MANAGED_ACCESS 1\n",
            "DIRECT_MANAGED_MEM_ACCESS_FROM_HOST 0\n",
            "ECC_ENABLED 1\n",
            "GENERIC_COMPRESSION_SUPPORTED 0\n",
            "GLOBAL_L1_CACHE_SUPPORTED 1\n",
            "GLOBAL_MEMORY_BUS_WIDTH 256\n",
            "GPU_OVERLAP 1\n",
            "HANDLE_TYPE_POSIX_FILE_DESCRIPTOR_SUPPORTED 1\n",
            "HANDLE_TYPE_WIN32_HANDLE_SUPPORTED 0\n",
            "HANDLE_TYPE_WIN32_KMT_HANDLE_SUPPORTED 0\n",
            "HOST_NATIVE_ATOMIC_SUPPORTED 0\n",
            "INTEGRATED 0\n",
            "KERNEL_EXEC_TIMEOUT 0\n",
            "L2_CACHE_SIZE 4194304\n",
            "LOCAL_L1_CACHE_SUPPORTED 1\n",
            "MANAGED_MEMORY 1\n",
            "MAXIMUM_SURFACE1D_LAYERED_LAYERS 2048\n",
            "MAXIMUM_SURFACE1D_LAYERED_WIDTH 32768\n",
            "MAXIMUM_SURFACE1D_WIDTH 32768\n",
            "MAXIMUM_SURFACE2D_HEIGHT 65536\n",
            "MAXIMUM_SURFACE2D_LAYERED_HEIGHT 32768\n",
            "MAXIMUM_SURFACE2D_LAYERED_LAYERS 2048\n",
            "MAXIMUM_SURFACE2D_LAYERED_WIDTH 32768\n",
            "MAXIMUM_SURFACE2D_WIDTH 131072\n",
            "MAXIMUM_SURFACE3D_DEPTH 16384\n",
            "MAXIMUM_SURFACE3D_HEIGHT 16384\n",
            "MAXIMUM_SURFACE3D_WIDTH 16384\n",
            "MAXIMUM_SURFACECUBEMAP_LAYERED_LAYERS 2046\n",
            "MAXIMUM_SURFACECUBEMAP_LAYERED_WIDTH 32768\n",
            "MAXIMUM_SURFACECUBEMAP_WIDTH 32768\n",
            "MAXIMUM_TEXTURE1D_LAYERED_LAYERS 2048\n",
            "MAXIMUM_TEXTURE1D_LAYERED_WIDTH 32768\n",
            "MAXIMUM_TEXTURE1D_LINEAR_WIDTH 268435456\n",
            "MAXIMUM_TEXTURE1D_MIPMAPPED_WIDTH 32768\n",
            "MAXIMUM_TEXTURE1D_WIDTH 131072\n",
            "MAXIMUM_TEXTURE2D_ARRAY_HEIGHT 32768\n",
            "MAXIMUM_TEXTURE2D_ARRAY_NUMSLICES 2048\n",
            "MAXIMUM_TEXTURE2D_ARRAY_WIDTH 32768\n",
            "MAXIMUM_TEXTURE2D_GATHER_HEIGHT 32768\n",
            "MAXIMUM_TEXTURE2D_GATHER_WIDTH 32768\n",
            "MAXIMUM_TEXTURE2D_HEIGHT 65536\n",
            "MAXIMUM_TEXTURE2D_LINEAR_HEIGHT 65000\n",
            "MAXIMUM_TEXTURE2D_LINEAR_PITCH 2097120\n",
            "MAXIMUM_TEXTURE2D_LINEAR_WIDTH 131072\n",
            "MAXIMUM_TEXTURE2D_MIPMAPPED_HEIGHT 32768\n",
            "MAXIMUM_TEXTURE2D_MIPMAPPED_WIDTH 32768\n",
            "MAXIMUM_TEXTURE2D_WIDTH 131072\n",
            "MAXIMUM_TEXTURE3D_DEPTH 16384\n",
            "MAXIMUM_TEXTURE3D_DEPTH_ALTERNATE 32768\n",
            "MAXIMUM_TEXTURE3D_HEIGHT 16384\n",
            "MAXIMUM_TEXTURE3D_HEIGHT_ALTERNATE 8192\n",
            "MAXIMUM_TEXTURE3D_WIDTH 16384\n",
            "MAXIMUM_TEXTURE3D_WIDTH_ALTERNATE 8192\n",
            "MAXIMUM_TEXTURECUBEMAP_LAYERED_LAYERS 2046\n",
            "MAXIMUM_TEXTURECUBEMAP_LAYERED_WIDTH 32768\n",
            "MAXIMUM_TEXTURECUBEMAP_WIDTH 32768\n",
            "MAX_BLOCKS_PER_MULTIPROCESSOR 16\n",
            "MAX_BLOCK_DIM_X 1024\n",
            "MAX_BLOCK_DIM_Y 1024\n",
            "MAX_BLOCK_DIM_Z 64\n",
            "MAX_GRID_DIM_X 2147483647\n",
            "MAX_GRID_DIM_Y 65535\n",
            "MAX_GRID_DIM_Z 65535\n",
            "MAX_PERSISTING_L2_CACHE_SIZE 0\n",
            "MAX_PITCH 2147483647\n",
            "MAX_REGISTERS_PER_BLOCK 65536\n",
            "MAX_REGISTERS_PER_MULTIPROCESSOR 65536\n",
            "MAX_SHARED_MEMORY_PER_BLOCK 49152\n",
            "MAX_SHARED_MEMORY_PER_BLOCK_OPTIN 65536\n",
            "MAX_SHARED_MEMORY_PER_MULTIPROCESSOR 65536\n",
            "MAX_THREADS_PER_BLOCK 1024\n",
            "MAX_THREADS_PER_MULTIPROCESSOR 1024\n",
            "MEMORY_CLOCK_RATE 5001000\n",
            "MULTIPROCESSOR_COUNT 40\n",
            "MULTI_GPU_BOARD 0\n",
            "MULTI_GPU_BOARD_GROUP_ID 0\n",
            "PAGEABLE_MEMORY_ACCESS 0\n",
            "PAGEABLE_MEMORY_ACCESS_USES_HOST_PAGE_TABLES 0\n",
            "PCI_BUS_ID 0\n",
            "PCI_DEVICE_ID 4\n",
            "PCI_DOMAIN_ID 0\n",
            "RESERVED_SHARED_MEMORY_PER_BLOCK 0\n",
            "SINGLE_TO_DOUBLE_PRECISION_PERF_RATIO 32\n",
            "STREAM_PRIORITIES_SUPPORTED 1\n",
            "SURFACE_ALIGNMENT 512\n",
            "TCC_DRIVER 0\n",
            "TEXTURE_ALIGNMENT 512\n",
            "TEXTURE_PITCH_ALIGNMENT 32\n",
            "TOTAL_CONSTANT_MEMORY 65536\n",
            "UNIFIED_ADDRESSING 1\n",
            "WARP_SIZE 32\n"
          ]
        }
      ]
    }
  ]
}